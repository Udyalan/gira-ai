import OpenAI from 'openai';
import { aiConfig, featureFlags } from '@/lib/config/feature-flags';
import { aiMemoryOperations, userOperations, User } from '@/lib/ai/supabase-client';

declare const process: {
  env: Record<string, string | undefined>;
  NODE_ENV?: string;
};

// Interfaces para o sistema de IA
export interface AIContext {
  userId?: string;
  userProfile?: User;
  conversationHistory?: Message[];
  currentModule: string;
  businessContext?: Record<string, any>;
  metadata?: Record<string, any>;
}

export interface Message {
  role: 'system' | 'user' | 'assistant';
  content: string;
  timestamp?: Date;
  metadata?: Record<string, any>;
}

export interface AIResponse {
  content: string;
  usage?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
  metadata?: Record<string, any>;
}

export interface AIAnalysis {
  summary: string;
  insights: string[];
  recommendations: string[];
  confidence: number;
  data?: Record<string, any>;
}

class OpenAIService {
  private client: OpenAI | null = null;
  private isInitialized = false;

  constructor() {
    this.initialize();
  }

  private initialize() {
    if (!featureFlags.AI_ENABLED) {
      console.log('ü§ñ IA desabilitada via feature flag');
      return;
    }

    if (!aiConfig.openai.apiKey) {
      console.warn('‚ö†Ô∏è OPENAI_API_KEY n√£o configurado');
      return;
    }

    try {
      this.client = new OpenAI({
        apiKey: aiConfig.openai.apiKey,
      });
      this.isInitialized = true;
      
      if (process?.env?.NODE_ENV === 'development') {
        console.log('ü§ñ OpenAI Service inicializado');
      }
    } catch (error) {
      console.error('‚ùå Erro ao inicializar OpenAI:', error);
    }
  }

  async generateResponse(
    prompt: string, 
    context: AIContext = { currentModule: 'general' }
  ): Promise<AIResponse> {
    if (!this.isInitialized || !this.client) {
      throw new Error('OpenAI n√£o est√° configurado ou habilitado');
    }

    try {
      // Construir contexto enriquecido
      const enrichedPrompt = await this.buildContextualPrompt(prompt, context);
      const systemPrompt = this.getSystemPrompt(context.currentModule, context.userProfile);

      // Chamar OpenAI
      const response = await this.client.chat.completions.create({
        model: aiConfig.openai.model,
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: enrichedPrompt }
        ],
        max_tokens: aiConfig.openai.maxTokens,
        temperature: aiConfig.openai.temperature,
      });

      const content = response.choices[0]?.message?.content || '';
      
      // Salvar intera√ß√£o na mem√≥ria (se usu√°rio estiver logado)
      if (context.userId && featureFlags.SUPABASE_ENABLED) {
        await this.storeInteraction(context.userId, {
          input: prompt,
          output: content,
          context: context,
          module: context.currentModule
        });
      }

      return {
        content,
        usage: {
          promptTokens: response.usage?.prompt_tokens || 0,
          completionTokens: response.usage?.completion_tokens || 0,
          totalTokens: response.usage?.total_tokens || 0,
        },
        metadata: {
          model: aiConfig.openai.model,
          module: context.currentModule,
          timestamp: new Date().toISOString(),
        }
      };

    } catch (error) {
      console.error('‚ùå Erro na chamada OpenAI:', error);
      throw new Error(`Erro ao processar solicita√ß√£o: ${error instanceof Error ? error.message : 'Erro desconhecido'}`);
    }
  }

  async analyzeData(data: any, analysisType: string, context?: AIContext): Promise<AIAnalysis> {
    if (!this.isInitialized || !this.client) {
      throw new Error('OpenAI n√£o est√° configurado');
    }

    const prompt = this.buildAnalysisPrompt(data, analysisType);
    const response = await this.generateResponse(prompt, {
      ...context,
      currentModule: `analysis_${analysisType}`
    });

    // Tentar extrair estrutura da resposta
    try {
      const analysis = JSON.parse(response.content);
      return {
        summary: analysis.summary || response.content,
        insights: analysis.insights || [],
        recommendations: analysis.recommendations || [],
        confidence: analysis.confidence || 0.8,
        data: analysis.data || {}
      };
    } catch {
      // Se n√£o conseguir parsear JSON, retornar formato b√°sico
      return {
        summary: response.content,
        insights: [],
        recommendations: [],
        confidence: 0.7
      };
    }
  }

  async testConnection(): Promise<{ connected: boolean; error?: string }> {
    if (!this.isInitialized || !this.client) {
      return { connected: false, error: 'OpenAI n√£o configurado' };
    }

    try {
      await this.client.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [{ role: 'user', content: 'Test' }],
        max_tokens: 5,
      });
      return { connected: true };
    } catch (error) {
      return { 
        connected: false, 
        error: error instanceof Error ? error.message : 'Erro de conex√£o'
      };
    }
  }

  // M√©todos privados
  private async buildContextualPrompt(prompt: string, context: AIContext): Promise<string> {
    let enrichedPrompt = prompt;

    // Adicionar contexto do usu√°rio
    if (context.userProfile) {
      enrichedPrompt = `
Contexto do usu√°rio:
- Nome: ${context.userProfile.name || 'N√£o informado'}
- Empresa: ${context.userProfile.company_id || 'N√£o informado'}
- Role: ${context.userProfile.role}

${enrichedPrompt}`;
    }

    // Adicionar hist√≥rico recente (se dispon√≠vel)
    if (context.userId && featureFlags.SUPABASE_ENABLED) {
      const recentMemories = await aiMemoryOperations.getByUser(context.userId, 'conversation');
      if (recentMemories.length > 0) {
        const recentContext = recentMemories
          .slice(0, 3) // √öltimas 3 intera√ß√µes
          .map(m => `- ${m.content.input}: ${m.content.output}`)
          .join('\n');
        
        enrichedPrompt = `
Contexto de conversas recentes:
${recentContext}

Solicita√ß√£o atual:
${enrichedPrompt}`;
      }
    }

    return enrichedPrompt;
  }

  private getSystemPrompt(module: string, userProfile?: User): string {
    const basePrompt = `
Voc√™ √© o assistente de IA do Gira.ai, uma plataforma completa de gest√£o empresarial.
Voc√™ √© especializado em fornecer insights inteligentes e solu√ß√µes pr√°ticas para empresas.

Caracter√≠sticas importantes:
- Seja sempre √∫til, preciso e profissional
- Forne√ßa respostas claras e acion√°veis
- Use dados quando dispon√≠vel para embasar recomenda√ß√µes
- Adapte sua linguagem ao perfil do usu√°rio
- Foque em solu√ß√µes pr√°ticas para neg√≥cios
`;

    const modulePrompts = {
      general: 'Voc√™ est√° auxiliando com quest√µes gerais de gest√£o empresarial.',
      financial: 'Voc√™ est√° no m√≥dulo financeiro. Foque em an√°lise financeira, fluxo de caixa, e recomenda√ß√µes econ√¥micas.',
      marketing: 'Voc√™ est√° no m√≥dulo de marketing. Ajude com estrat√©gias de marketing, cria√ß√£o de conte√∫do e an√°lise de engajamento.',
      whatsapp: 'Voc√™ est√° no m√≥dulo WhatsApp. Auxilie com automa√ß√£o de atendimento e comunica√ß√£o com clientes.',
      scheduling: 'Voc√™ est√° no m√≥dulo de agendamentos. Ajude com otimiza√ß√£o de agenda e gest√£o de tempo.',
      analytics: 'Voc√™ est√° no m√≥dulo de analytics. Foque em an√°lise de dados e gera√ß√£o de insights.',
      crm: 'Voc√™ est√° no m√≥dulo CRM. Auxilie com gest√£o de relacionamento com clientes.',
    };

    const modulePrompt = modulePrompts[module as keyof typeof modulePrompts] || modulePrompts.general;

    let roleContext = '';
    if (userProfile?.role) {
      const rolePrompts = {
        admin: 'O usu√°rio √© um administrador do sistema. Forne√ßa insights estrat√©gicos e vis√£o macro.',
        company_admin: 'O usu√°rio √© um administrador da empresa. Foque em gest√£o operacional e tomada de decis√£o.',
        manager: 'O usu√°rio √© um gerente. Auxilie com gest√£o de equipe e processos.',
        user: 'O usu√°rio √© um colaborador. Forne√ßa orienta√ß√µes pr√°ticas para suas tarefas.'
      };
      roleContext = rolePrompts[userProfile.role] || '';
    }

    return `${basePrompt}\n\n${modulePrompt}\n\n${roleContext}`.trim();
  }

  private buildAnalysisPrompt(data: any, analysisType: string): string {
    const basePrompt = `
Analise os seguintes dados e forne√ßa insights acion√°veis.
Retorne a resposta em formato JSON com as seguintes chaves:
- summary: resumo executivo da an√°lise
- insights: array de insights principais encontrados
- recommendations: array de recomenda√ß√µes pr√°ticas
- confidence: n√∫mero entre 0 e 1 indicando confian√ßa na an√°lise
- data: dados processados ou m√©tricas relevantes

Tipo de an√°lise: ${analysisType}
Dados para an√°lise:
${JSON.stringify(data, null, 2)}
`;

    return basePrompt;
  }

  private async storeInteraction(
    userId: string, 
    interaction: {
      input: string;
      output: string;
      context: AIContext;
      module: string;
    }
  ): Promise<void> {
    try {
      await aiMemoryOperations.store({
        user_id: userId,
        context_type: 'conversation',
        content: {
          input: interaction.input,
          output: interaction.output,
          module: interaction.module,
          timestamp: new Date().toISOString()
        },
        relevance_score: 1.0,
      });
    } catch (error) {
      console.error('‚ùå Erro ao salvar intera√ß√£o:', error);
    }
  }
}

// Inst√¢ncia singleton do servi√ßo
export const openaiService = new OpenAIService();

// Fun√ß√£o utilit√°ria para verificar se a IA est√° dispon√≠vel
export function isAIAvailable(): boolean {
  return featureFlags.AI_ENABLED && aiConfig.openai.apiKey !== undefined;
}

// Tipos j√° exportados acima nas declara√ß√µes das interfaces